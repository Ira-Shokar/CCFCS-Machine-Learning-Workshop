{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"left\">\n",
    "  <img src=\"climate_net/img/CCfCS.png\" width=\"100\" />\n",
    "  <img src=\"climate_net/img/cam.png\" width=\"100\" />\n",
    "</p>\n",
    "\n",
    "# CCfCS ML for Climate Science -  Notebook 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first part of this interactive introductory machine learning tutorial workshop. We'll start by loading in the required external libraries for use in python. \n",
    "\n",
    "*If running in Google Colab, then uncomment and run the following (You must have first added a shortcut to your GDrive - see [here](https://github.com/Ira-Shokar/CCFCS-Machine-Learning-Workshop)):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "#%pip install -r /content/drive/MyDrive/climate_net/env.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pylab as plt\n",
    "import cmocean \n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import urllib.request as urllib2\n",
    "import requests\n",
    "import xarray as xr\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in some example data file. For our purposes we are using the ClimateNet dataset described here https://gmd.copernicus.org/articles/14/107/2021/ which itself takes snapshots from the Community Atmospheric Model (CAM5.1) output: https://www.cesm.ucar.edu/models/cesm1.0/cam/docs/description/cam5_desc.pdf. Don't worry too much about the specifics of the data, we are more interested in exploring here. \n",
    "\n",
    "First we construct a python string containing the location of the file then load this as an 'xarray' (a nice way of viewing and handling the tabulated data).\n",
    "\n",
    "*If running in Google Colab, make sure to follow the instructions at the top of the page, before uncommenting the second code cell below and running that instead of the following.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('climate_net/test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = xr.open_dataset('/content/drive/MyDrive/climate_net/test.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the tabulated data (note this is interactive in a jupter notebook). Note the output cell below is interactive: try for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is horizontally gridded with dimensions 768 x 1152. Let us load the latitude and longitude coordinates of each grid cell into memory. We can select coordinates from an xarray by using the dataset.coordinate notation, then convert the resulting dataset to a regular printable array using .values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the values of the latitude and longitude from the dataset, and print the array of longitude values (which unsurprisingly go from 0 to 360)\n",
    "lon = ds.lon.values\n",
    "lat = ds.lat.values \n",
    "print(lon) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exactly the same way, we can load in specific data variables. Remember you can check out what these are using the interactive xarray cell above. Note that this results in an array with an extra dimension, which corresponds to snapshots at different times (here we have 61 different times). We will worry about these in a moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in e.g. zonal winds at 850mb pressure surface. We can see that this is an array with three dimensions. \n",
    "#The first dimension is time.\n",
    "#The second two dimensions are latitude and longitude.\n",
    "U850 = ds.U850.values\n",
    "print(U850.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us just select one time snapshot: the first one, for convenience. We can select along the first dimension using square brackets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the first column of the first dimension using square brackets (python starts indexing at 0) and print values from the 2D array.\n",
    "#These are the values of U850 at each latitude and longitude\n",
    "print(U850[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visualize the data in some useful way. Since we have values of different climate variables at each latitude and longitude, it makes sense to do a contour plot. We can do special contour plots for data in latitude-longitude format using the module cartopy loaded above. This is set up as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection=ccrs.PlateCarree();\n",
    "figsize = (12,5)\n",
    "# Some other projections we might try (try uncommenting these!)\n",
    "# projection=ccrs.Robinson();\n",
    "# projection=ccrs.LambertCylindrical();\n",
    "\n",
    "#for future reference, define a function to set up our map\n",
    "def map_setup(figsize,projection):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='k')\n",
    "    ax.gridlines(draw_labels=True, color='k', linestyle='--')  \n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "image = ax.pcolormesh(lon, lat,U850[0], transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance, vmin=-40,vmax=40) \n",
    "#The cmocean module has very nice colour maps. They are listed here: https://matplotlib.org/cmocean/\n",
    "fig.colorbar(image, ax=ax, label='U850')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the characteristic strong westerly winds over the Southern ocean in the above plot. Now try loading in some other variables from the dataset and plotting those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection=ccrs.PlateCarree();\n",
    "figsize = (12,5)\n",
    "\n",
    "V850 = ds.V850.values\n",
    "#Try replacing V850 with another data variable! Note you might need to change the parameters vmin and vmax which control the maximum and minimum colour scale levels.\n",
    "\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "image = ax.pcolormesh(lon, lat,V850[0], transform=ccrs.PlateCarree(), cmap=cmocean.cm.curl, vmin=-30, vmax=30) #Note different colormap!\n",
    "fig.colorbar(image, ax=ax, label='V850')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each snapshot in this dataset has been labelled with extreme weather events (see the LABELS data variable above). We can plot them using the below: here orange corresponds to an atmospheric river and purple corresponds to a tropical cyclone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection=ccrs.PlateCarree();\n",
    "figsize = (12,5)\n",
    "\n",
    "labels = ds.LABELS.values\n",
    "\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "image = ax.contourf(lon, lat,labels[0], transform=ccrs.PlateCarree(), levels=np.linspace(0.5,2,3), alpha=0.8, cmap=cmocean.cm.thermal) \n",
    "fig.colorbar(image, ax=ax, label='V850')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore snapshots taken from different times. These are saved in a slightly unusual but fairly instructive format: data-YYYY-MM-DD-01-1.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ds.time.values\n",
    "print(time) #A long array of all the different times from the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projection=ccrs.PlateCarree();\n",
    "figsize = (12,5)\n",
    "TMQ = ds.TMQ.values\n",
    "\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "image = ax.pcolormesh(lon, lat,TMQ[41], transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance) \n",
    "#The cmocean module has very nice colour maps. They are listed here: https://matplotlib.org/cmocean/\n",
    "fig.colorbar(image, ax=ax, label='PSL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the location of extreme extreme weather events for this snapshot (potentially a wet day for Cambridge!): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection=ccrs.PlateCarree();\n",
    "figsize = (12,5)\n",
    "\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "image = ax.contourf(lon, lat,labels[41], transform=ccrs.PlateCarree(), levels=np.linspace(0.5,2,3), alpha=0.8, cmap=cmocean.cm.thermal) \n",
    "fig.colorbar(image, ax=ax, label='V850')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example dataset we are going to try and explore which variables might be important for determining whether a given location is experiencing an extreme weather event. To make things more tractable let us first reduce the dimensions of our dataset. The simplest way to do this is to sparse, using the [::sparse_factor] notation.\n",
    "\n",
    "Below we plot the total precipitable water with contours of extreme events on top, using a sparsed version of the snapshot we just looked at. Note the pattern that starts to emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = map_setup(figsize,projection) \n",
    "ax.pcolormesh(lon[::16], lat[::16],TMQ[41][::16,::16], transform=ccrs.PlateCarree(),cmap=cmocean.cm.balance) \n",
    "ax.contour(lon[::16], lat[::16],labels[41][::16,::16], transform=ccrs.PlateCarree(),cmap=cmocean.cm.balance) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly more sophisticated way to reduce dimensionality is to first perform a 2d moving average (essentially blurring the image) and then sparsing the resulting array. In this way each point represents an average value over an area surrounding that pixel. Formally, this is carried out by convolving the array with a Gaussian kernel, Luckily for us there is a function in scipy that does this automatically. Try playing around with the value of sigma (the variance of the convolution kernel) and see what happens below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "filtered_TMQ = gaussian_filter(TMQ[41],sigma = 10)\n",
    "plt.pcolormesh(lon[::16], lat[::16],filtered_TMQ[::16,::16],transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance) \n",
    "plt.contour(lon[::16], lat[::16],labels[41][::16,::16],transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above it looks like there is a link between the variable TMQ and atmospheric rivers. What other variables might be linked? Let's explore this further using a scatter plot. Try playing around with different variables and see if you notice any patterns. Remember to keep in mind here that we are really just exploring at the moment: the aim of all of this is to give us an idea about how we might best construct a model for predicting these extreme weather events. For example, which variables might be most useful for indicating the presence of an atmospheric river in a particular cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reprint the dataset here just for reference (so you don't have to scroll all the way back up!)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "#Choose your variables here! Remember you can refer to the xarray and code for selecting a particular variable above.\n",
    "#Note these variables have been sparsed with a Gaussian filter.\n",
    "\n",
    "TMQ = ds.TMQ.values\n",
    "PRECT = ds.PRECT.values\n",
    "var1 = gaussian_filter(TMQ[41],sigma = 10)[::16,::16]\n",
    "var2 = gaussian_filter(PRECT[41],sigma = 10)[::16,::16]\n",
    "\n",
    "#Now do a scatter plot between these two variables, colouring the points by their label:\n",
    "plt.scatter(var1.flatten(), np.log10(var2.flatten()), c=labels[0,::16,::16].flatten(), cmap=cmocean.cm.thermal)\n",
    "plt.colorbar(label='LABEL')\n",
    "plt.xlabel('Total precipitable water')\n",
    "plt.ylabel('log10(precipitation rate)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots are quite nice for labelling tasks (such as determining an extreme weather event) since we can add an extra dimension by colouring the points. However for large datasets it can sometimes be difficult to spot patterns when very dense clusters of points exist. With too high a number of data points plotting each individual point eventually becomes intractable and so it makes sense to bin the data first and then plot it using a 2d histogram. This is particularly appropriate in our case, say, if we want to plot the trends over all snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMQ = ds.TMQ.values\n",
    "PRECT = ds.PRECT.values\n",
    "\n",
    "var1 = gaussian_filter(TMQ,sigma = [0,10,10])[::16,::16]\n",
    "var2 = gaussian_filter(PRECT,sigma = [0,10,10])[::16,::16]\n",
    "hist2d = np.histogram2d(np.log10(var2.flatten()), var1.flatten(), bins=20)\n",
    "plt.figure(figsize=(10,5))\n",
    "ax=plt.gca()\n",
    "im = ax.pcolormesh(hist2d[2], hist2d[1], hist2d[0], vmin=1, cmap='Spectral_r')\n",
    "plt.colorbar(im, label='Frequency')\n",
    "plt.xlabel('Total precipitable water')\n",
    "plt.ylabel('log10(precipitation rate)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our physical intuition to help us decode correlations. For example, you would probably imagine that the dynamics near the tropics are reasonably different to the dynamics at higher latitudes. We can filter our dataset accordingly using the xarray.where command. Note that this command is also useful for data cleaning purposes. You can play around with the filter below and see what correlations start to emerge more strongly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = ds.where(abs(ds.lat) < 25, drop=True)\n",
    "print(filtered_ds.lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do exactly the same 2d histogram plot as above but for the filtered dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMQ = filtered_ds.TMQ.values\n",
    "PRECT = filtered_ds.PRECT.values\n",
    "\n",
    "var1 = gaussian_filter(TMQ,sigma = [0,10,10])[::16,::16]\n",
    "var2 = gaussian_filter(PRECT,sigma = [0,10,10])[::16,::16]\n",
    "hist2d = np.histogram2d(np.log10(var2.flatten()), var1.flatten(), bins=20)\n",
    "plt.figure(figsize=(10,5))\n",
    "ax=plt.gca()\n",
    "im = ax.pcolormesh(hist2d[2], hist2d[1], hist2d[0], vmin=1, cmap='Spectral_r')\n",
    "plt.colorbar(im, label='Frequency')\n",
    "plt.xlabel('Total precipitable water')\n",
    "plt.ylabel('log10(precipitation rate)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This serves as a very basic introduction to how you might start to build 'physics-informed' models. Though this is perhaps a mysterious term, very often the encoded physics is actually quite a simple conceptual idea that is captured in, for example, the inputs fed into the model. It is good to have some kind of idea about the sort of physics you expect your model to pick up on before designing it: this is likely to make the conclusions you draw from the model much more meaningful. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
